import sys
import os
import pandas as pd

# Load run and replicate information from the RunsbyExperiment.tsv input file (user must provide)
SAMPLES_FILE = pd.read_csv("RunsByExperiment.tsv", sep="\t")


SAMPLE_LIST = list(set(SAMPLES_FILE["Run"].values.tolist()))
REPLICATE_LIST = list(set(SAMPLES_FILE["Replicate"].values.tolist()))
# create the Sample tab-delimited text file indicating biological replicate relationships
#
replicate_relationship= ""
for index, row in SAMPLES_FILE.iterrows():
    replicate_relationship += f"{row['Sample']}\t{row['Replicate']}\n"
with open('replication_relationship.txt', 'w') as f:
    f.write(replicate_relationship)

# Load the config file as a dictionary
cf = open("config.json")
config_dict = json.load(cf)
#print(config_dict)
cf.close()

# Load deg_samples.txt for DEG calculation (user must provide)
contrasts = os.path.exists(config_dict["sample_contrast"])
if config_dict["runDEG"] == "yes":
    if contrasts:
        CONTRASTS_FILE = pd.read_csv(config_dict["sample_contrast"], sep="\t", header=None)
        cTop = CONTRASTS_FILE.iloc[-1][0]
        cBottom = CONTRASTS_FILE.iloc[-1][1]
    else:
        cTop = ""
        cBottom = ""
else:
    cTop = ""
    cBottom = ""

# Create replicate output folders
os.makedirs("output/counts/", exist_ok=True)
os.makedirs("output/logs/", exist_ok=True)
os.makedirs("output/DEG/", exist_ok=True)
if config_dict["readCounting"] == "RSEM":
    os.makedirs("output/counts/RSEM/", exist_ok=True)
else:
    os.makedirs("output/counts/featureCounts/", exist_ok=True)
    os.makedirs("output/counts/htseq/", exist_ok=True)
    os.makedirs("output/counts/tpmcalculator", exist_ok=True)

for rep in REPLICATE_LIST:
    os.makedirs("output/" + rep + "/bam/", exist_ok=True)
    os.makedirs("output/" + rep + "/raw/", exist_ok=True)
    os.makedirs("output/" + rep + "/logs/", exist_ok=True)
    os.makedirs("output/" + rep + "/trim/", exist_ok=True)

# Get the nomenclature for paired end raw data from config.json
PAIR_LIST= config_dict["PAIR_LIST"]

# Check for an indexed reference genome or prepared genome for RSEM
if config_dict["readCounting"] == "RSEM":
    if not os.path.exists(f"{config_dict['RSEM_prepared_genome']}.seq"):
        sys.exit(f"Cannot locate '{config_dict['RSEM_prepared_genome']}'.\nProvide a reference genome prepared with 'rsem-prepare-reference' to use RSEM.\nExiting...")
else:
    for ref in config_dict["ref"]:
        if not os.path.exists(ref):
            sys.exit("The " + ref + " file is missing.\nHave you provided the correct paths to an indexed a refernce genome?\nExiting...")

configfile: "config.json"

# Generate a list of all target output files
def allInput():
    if config_dict["readCounting"] == "RSEM":
        inputs = ["output/counts/RSEM/RSEM_TPM.tsv.average.tsv",
                "output/counts/RSEM/RSEM_TPM.tsv",
                "output/counts/RSEM/RSEM_expected_count.tsv.minRow10.CPM.log2.centered.prcomp.principal_components.pdf"]
    else:
        inputs = ["output/counts/featureCounts/featureCounts.cnt",
              "output/counts/htseq/htseq-count.tsv",
              "output/counts/featureCounts/featureCounts.tpm.tsv",
              "output/counts/featureCounts/featureCounts.fpkm.tsv",
              "output/counts/htseq/htseq-count.tpm.tsv",
              "output/counts/htseq/htseq-count.fpkm.tsv",
              "output/counts/tpmcalculator/tpmcalculator-merged.tsv",
              "output/counts/tpmcalculator/tpmcalculator-merged.tsv.average.tsv",
              "output/counts/featureCounts/featureCounts.tpm.tsv.average.tsv",
              "output/counts/htseq/htseq-count.tpm.tsv.average.tsv",
              "output/counts/featureCounts/featureCount_clean.cnt",
              "output/counts/htseq/htseq-count.tsv.minRow10.CPM.log2.centered.prcomp.principal_components.pdf",
              "output/counts/featureCounts/featureCount_clean.cnt.minRow10.CPM.log2.centered.prcomp.principal_components.pdf"]
    for replicate in REPLICATE_LIST:
        if config_dict["readCounting"] == "RSEM":
            inputs.append("output/" + replicate + "/bam/" + replicate + ".xs.bamAligned.toTranscriptome.out.bam")
            inputs.append("output/counts/RSEM/" + replicate + ".genes.results")
        else:
            inputs.append("output/counts/tpmcalculator/" + replicate + "_genes.out")
            inputs.append("output/" + replicate + "/bam/" + replicate + ".bamAligned.sortedByCoord.out.bam")
        for pair in PAIR_LIST:
            inputs.append("output/" + replicate + "/trim/" + replicate + pair + ".fq.gz")
            inputs.append("output/" + replicate + "/raw/" + replicate + pair + "_fastqc.zip")
            inputs.append("output/" + replicate + "/raw/" + replicate + pair + ".fastq.gz")
    if config_dict["runDEG"] == "yes":
        if config_dict["readCounting"] == "RSEM":
            inputs.append("output/DEG/RSEM_expected_count.tsv." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results")
            inputs.append("output/DEG/RSEM_expected_count.tsv." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results.P0.01_C1.DE.subset")
        else:
            inputs.append("output/DEG/featureCount_clean.cnt." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results.P0.01_C1.DE.subset")
            inputs.append("output/DEG/featureCount_clean.cnt." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results")
            inputs.append("output/DEG/htseq-count.tsv." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results")
            inputs.append("output/DEG/htseq-count.tsv." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results.P0.01_C1.DE.subset")
    return(inputs)

rule all:
    input:
        allInput()

rule importRaw:
    output: "output/{replicate}/raw/{replicate}_{pair}.fastq.gz"
    message: "Importing raw data: ln " + config["rawInputDir"] + "/{wildcards.replicate}_{wildcards.pair}.fastq.gz {output}"
    threads: config["threads"]["importRaw"]
    run:
        shell("ln -s " + config["rawInputDir"] + "/{wildcards.replicate}_{wildcards.pair}.fastq.gz {output}")

rule fastqc_raw:
    input:
        "output/{replicate}/raw/{replicate}" + PAIR_LIST[0] + ".fastq.gz",
        "output/{replicate}/raw/{replicate}" + PAIR_LIST[1] + ".fastq.gz"
    output:
        "output/{replicate}/raw/{replicate}" + PAIR_LIST[0] + "_fastqc.zip",
        "output/{replicate}/raw/{replicate}" + PAIR_LIST[1] + "_fastqc.zip"
    message: "-----Running Fastqc_raw {wildcards.replicate}-----"
    threads: config["threads"]["fastqc_raw"]
    log: "output/{replicate}/logs/{replicate}_raw_fastqc.log"
    run:
        # Run quality control on raw reads
        shell("fastqc --threads {threads} {input} --outdir output/{wildcards.replicate}/raw/ 2> {log}")

rule trim:
    input:
        fwd_fastq = "output/{replicate}/raw/{replicate}" + PAIR_LIST[0] + ".fastq.gz",
        rev_fastq = "output/{replicate}/raw/{replicate}" + PAIR_LIST[1] + ".fastq.gz",
    output:
        fwd_fastq = "output/{replicate}/trim/{replicate}" + PAIR_LIST[0] + ".fq.gz",
        rev_fastq = "output/{replicate}/trim/{replicate}" + PAIR_LIST[1] + ".fq.gz"
    message: "-----Trimming {wildcards.replicate}-----"
    log: "output/{replicate}/logs/{replicate}_trim.log"
    threads: config["threads"]["trim"]
    run:
        # Trim reads using fastp
        shell("fastp --detect_adapter_for_pe \
        --overrepresentation_analysis \
        --cut_right \
        --thread {threads} \
        --html output/{wildcards.replicate}/trim/{wildcards.replicate}.fastp.html \
        --json output/{wildcards.replicate}/trim/{wildcards.replicate}.fastp.json \
        -i {input.fwd_fastq} -I  {input.rev_fastq} \
        -o {output.fwd_fastq} -O {output.rev_fastq} 2> {log}")
        # Run quality control on trimmed reads
        shell("fastqc --threads {threads} {output}")

rule alignSTAR:
    input:
        fwd_fastq = "output/{replicate}/trim/{replicate}" + PAIR_LIST[0] + ".fq.gz",
        rev_fastq = "output/{replicate}/trim/{replicate}" + PAIR_LIST[1] + ".fq.gz"
    output:"output/{replicate}/bam/{replicate}.bamAligned.sortedByCoord.out.bam"
    message: "-----Aligning {wildcards.replicate}-----"
    log: "output/{replicate}/logs/{replicate}_alignRSEM.log"
    threads: config["threads"]["align"]
    run:
        # Calculate run-level alignments to reference
        shell("STAR --runMode alignReads --runThreadN {threads} \
              --outFilterMultimapNmax 100 --alignIntronMin 25 --alignIntronMax 50000 \
              --quantMode TranscriptomeSAM GeneCounts \
              --genomeDir " + config["genomeDir"]  + " \
              --readFilesCommand gunzip -c --readFilesIn {input.fwd_fastq} {input.rev_fastq} \
              --outSAMtype BAM SortedByCoordinate --outFileNamePrefix output/{wildcards.replicate}/bam/{wildcards.replicate}.bam  \
		2> {log}")
        # Perform check on output bam file to ensure it is not corrupted
        shell("echo '--------Checking {output}----------'")
        shell("set +e")
        shell("if ! samtools flagstat {output}; then echo 'samtools flagstat found errors in {output}. Check log here: {log}. Exiting......' && exit 1; fi")
        shell("samtools index -@ {threads} {output}")

rule alignRSEM:
    input:
        fwd_fastq = "output/{replicate}/trim/{replicate}" + PAIR_LIST[0] + ".fq.gz",
        rev_fastq = "output/{replicate}/trim/{replicate}" + PAIR_LIST[1] + ".fq.gz"
    output:"output/{replicate}/bam/{replicate}.xs.bamAligned.toTranscriptome.out.bam"
    message: "-----Aligning for RSEM: {wildcards.replicate}-----"
    log: "output/{replicate}/logs/{replicate}_alignRSEM.log"
    threads: config["threads"]["align"]
    run:
        # Calculate run-level alignments to reference
        shell("STAR --runMode alignReads --runThreadN {threads} \
            --outFilterMultimapNmax 10 --alignIntronMin 25 --alignIntronMax 25000 \
            --genomeDir " + config["genomeDir"]  + " \
            --readFilesCommand gunzip -c --readFilesIn {input.fwd_fastq} {input.rev_fastq} \
            --outSAMtype BAM SortedByCoordinate --quantMode TranscriptomeSAM \
            --quantTranscriptomeBan IndelSoftclipSingleend  \
            --alignEndsType EndToEnd  \
            --outFileNamePrefix output/{wildcards.replicate}/bam/{wildcards.replicate}.xs.bam")

rule calculateRSEMExpression:
    input: "output/{replicate}/bam/{replicate}.xs.bamAligned.toTranscriptome.out.bam"
    output: "output/counts/RSEM/{replicate}.genes.results"
    message:"-----  Calculating RSEM expression: {wildcards.replicate}------"
    threads: config["threads"]["calculateRSEMExpression"]
    run:
        shell("rsem-calculate-expression --bam --no-bam-output -p {threads} \
            --paired-end {input} " + config["RSEM_prepared_genome"] + " output/counts/RSEM/{wildcards.replicate}")

rule TPMCalculator:
    input: "output/{replicate}/bam/{replicate}.bamAligned.sortedByCoord.out.bam"
    output: "output/counts/tpmcalculator/{replicate}_genes.out"
    message: "------- Calculating TPM: {wildcards.replicate} --------"
    #log: "output/counts/tpmcalculator/tpm-calculator.log"
    threads: config["threads"]["TPMCalculator"]
    run:
        # Perform TPM calculation using each replicate-level bam file
        shell("TPMCalculator \
               -k gene_id \
               -t transcript_id \
               -o 0 \
               -g " + config_dict["GTFname"] + " -b {input}")
        # Move output files to proper location
        shell("mv {wildcards.replicate}.bamAligned.sortedByCoord.out_genes.out output/counts/tpmcalculator/{wildcards.replicate}_genes.out")
        shell("mv {wildcards.replicate}.bamAligned.sortedByCoord.out_genes.ent output/counts/tpmcalculator/{wildcards.replicate}_genes.ent")
        shell("mv {wildcards.replicate}.bamAligned.sortedByCoord.out_genes.uni output/counts/tpmcalculator/{wildcards.replicate}_genes.uni")

rule mergeTPMCalculator:
    input: expand("output/counts/tpmcalculator/{replicate}_genes.out", replicate=REPLICATE_LIST)
    output: "output/counts/tpmcalculator/tpmcalculator-merged.tsv"
    message: "--------Merging TPMCalculator results--------"
    threads: config["threads"]["mergeTPMCalculator"]
    run:
        shell("./scripts/mergeTPMCalculator.py {input}")

rule featureCounts:
    message: "-----Generating raw counts (featureCounts)-----"
    input: expand("output/{replicate}/bam/{replicate}.bamAligned.sortedByCoord.out.bam", replicate=REPLICATE_LIST)
    output: 
        raw = "output/counts/featureCounts/featureCounts.cnt",
        cleaned = "output/counts/featureCounts/featureCount_clean.cnt"
    log: "output/counts/featureCounts/featureCounts.log"
    threads: config["threads"]["featureCount"]
    run:
        # Calculate raw counts from all replicate-level bam files
        shell("featureCounts \
                -o {output.raw} \
                -T {threads} \
                -Q 1 \
                -p -M \
                -g gene_id \
                -a " + config_dict["GTFname"] + " {input} \
    		2> {log}")
        # Remove the featureCounts header line from output file and re-format the output names
        shell("cat {output.raw} |  egrep -v '#' | \
                sed 's/\Aligned\.sortedByCoord\.out\.bam//g; s/\.bam//g; s/output\/[A-Za-z0-9_-]*\/bam\///g' \
                > {output.cleaned}")

rule HTseq:
    message: "-----Generating raw counts (HTseq)-----"
    input: expand("output/{replicate}/bam/{replicate}.bamAligned.sortedByCoord.out.bam", replicate=REPLICATE_LIST)
    output: "output/counts/htseq/htseq-count.tsv"
    log: "output/counts/htseq/HTseq.log"
    threads: config["threads"]["HTseq"]
    run:
        # Compute raw gene-wise counts
        shell("htseq-count \
                 --format bam \
                 --order pos \
                 --mode union \
		 --stranded=no \
                 --type exon \
                 --idattr gene_id \
                 --nprocesses {threads} \
                 --counts_output {output} \
                 {input} " + config_dict["GTFname"] + "  \
                 &> {log}")
        # Add headers to label HTseq tsv output fields
        shell("sed -i '1 i\gene\\t" + "\\t".join(input) + "' {output} &&\
               sed -i s/'output\/[A-Za-z0-9_-]*\/bam\/'//g {output}")
        # Re-format treatment names in HTseq output
        shell("sed -i 's/\.bamAligned.sortedByCoord.out.bam//g' {output}")

rule normalizeFeatureCounts:
    input:
        "output/counts/featureCounts/featureCount_clean.cnt"
    output:
        "output/counts/featureCounts/featureCounts.tpm.tsv",
        "output/counts/featureCounts/featureCounts.fpkm.tsv"
    message: "------- Normalizing featureCounts ---------"
    log: "output/counts/normalize_featureCounts.log"
    threads: config["threads"]["normalizeFeatureCounts"]
    run:
        # Compute TPM and FPKM values featureCounts raw counts
        shell("python ./scripts/normalizeCounts.py featureCounts " + config["GTFname"] + " {input} output/counts/featureCounts/featureCounts " + config["genomeDir"])

rule normalizeHTseq:
    input:
        "output/counts/htseq/htseq-count.tsv"
    output:
        tpm = "output/counts/htseq/htseq-count.tpm.tsv",
        fpkm = "output/counts/htseq/htseq-count.fpkm.tsv"
    message: "------- Normalizing HTseq ---------"
    log: "output/counts/htseq/normalize_HTseq.log"
    threads: config["threads"]["normalizeHTseq"]
    run:
        # Generate exon lengths from gtf file
        shell("./scripts/calc_cdna_len.py " + config["GTFname"] + " gene_id > ref/cds_length.tsv")
        # Compute TPM and FPKM values HTseq raw counts
        shell("python scripts/normalizeCounts.py HTseq " + config["GTFname"] + " {input} output/counts/htseq/htseq-count " + config["genomeDir"])

rule DEG_featureCounts:
    input: 
        featureCounts = "output/counts/featureCounts/featureCount_clean.cnt"
    output: 
        featureCounts = "output/DEG/featureCount_clean.cnt." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results",
        featureCounts_subset = "output/DEG/featureCount_clean.cnt." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results.P0.01_C1.DE.subset",
        PtR = "output/counts/featureCounts/featureCount_clean.cnt.minRow10.CPM.log2.centered.prcomp.principal_components.pdf"

    message: "-------Calculating DEGs {output}---------"
    log: "output/DEG/DEG_featureCounts.log"
    params:
        replication = os.path.join(os.getcwd(), config_dict["replication_relationship"]),
        matrix =  os.path.join(os.getcwd(), "output/counts/featureCounts/featureCount_clean.cnt")
    threads: config["threads"]["DEG_featureCounts"]
    run:
        # Compute differentially expressed genes based on deg_samples.txt
        shell("run_DE_analysis.pl --matrix {input.featureCounts} --method DESeq2 --samples_file " + config_dict["replication_relationship"] + " --contrasts " + config_dict["sample_contrast"] + " --output output/DEG")
        shell("cd output/DEG && analyze_diff_expr.pl --samples {params.replication} --matrix {params.matrix} -P 0.001 -C 2")
        shell("cd output/DEG && analyze_diff_expr.pl --samples {params.replication} --matrix {params.matrix} -P 0.01 -C 1")
        shell("cd output/counts/featureCounts && PtR --matrix featureCount_clean.cnt --min_rowSums 10 -s {params.replication}  --log2 --CPM --sample_cor_matrix --CPM --center_rows --prin_comp 3")

rule DEG_HTseq:
    input:
        HTseq = "output/counts/htseq/htseq-count.tsv"
    output:
        HTseq = "output/DEG/htseq-count.tsv." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results",
        HTSeq_subset =  "output/DEG/htseq-count.tsv." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results.P0.01_C1.DE.subset",
        PtR = "output/counts/htseq/htseq-count.tsv.minRow10.CPM.log2.centered.prcomp.principal_components.pdf"

    message: "-------Calculating DEGs {output}---------"
    log: "output/DEG/DEG_HTseq.log"
    params:
         replication = os.path.join(os.getcwd(), config_dict["replication_relationship"]),
         matrix =  os.path.join(os.getcwd(), "output/counts/htseq/htseq-count.tsv")
    threads: config["threads"]["DEG_HTseq"]
    run:
        # Compute differentially expressed genes based on deg_samples.txt
        shell("run_DE_analysis.pl --matrix {input.HTseq} --method DESeq2 --samples_file" + config_dict["replication_relationship"] + "--contrasts " + config_dict["sample_contrast"] + " --output output/DEG")
        shell("cd output/DEG && analyze_diff_expr.pl --samples {params.replication} --matrix {params.matrix} -P 0.001 -C 2")
        shell("cd output/DEG && analyze_diff_expr.pl --samples {params.replication} --matrix {params.matrix} -P 0.01 -C 1")
        shell("cd output/counts/htseq && PtR --matrix htseq-count.tsv --min_rowSums 10 -s {params.replication}  --log2 --CPM --sample_cor_matrix --CPM --center_rows --prin_comp 3")
def input_DEG_RSEM(wildcards):
    inputs = expand("output/counts/RSEM/{replicate}.genes.results", replicate=REPLICATE_LIST)
    return(inputs)

rule DEG_RSEM:
    input: input_DEG_RSEM
    output: 
        "output/DEG/RSEM_expected_count.tsv." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results",
        "output/DEG/RSEM_expected_count.tsv." + cTop  + "_vs_" + cBottom  + ".DESeq2.DE_results.P0.01_C1.DE.subset",
        "output/counts/RSEM/RSEM_expected_count.tsv.minRow10.CPM.log2.centered.prcomp.principal_components.pdf"
    message: "-------Calculating RSEM DEGs {output}---------"
    log: "output/DEG/DEG_RSEM.log"
    threads: config["threads"]["DEG_RSEM"]
    params:
        replication = os.path.join(os.getcwd(), config_dict["replication_relationship"]),
        matrix =  os.path.join(os.getcwd(), "output/counts/RSEM/RSEM_TPM.tsv")
    run:
        # Merge RESM output files into matrix
        shell("python ./scripts/makeRSEMMatrix.py RunsByExperiment.tsv output/counts/RSEM expected_count")
        # Compute differentially expressed genes based on deg_samples.txt
        shell("run_DE_analysis.pl --matrix output/counts/RSEM/RSEM_expected_count.tsv --method DESeq2 --samples_file " + config_dict["replication_relationship"] + " --contrasts " + config_dict["sample_contrast"] + " --output output/DEG")
        shell("cd output/counts/RSEM && PtR --matrix RSEM_expected_count.tsv --min_rowSums 10 -s {params.replication}  --log2 --CPM --sample_cor_matrix --CPM --center_rows --prin_comp 3")
        shell("cd output/DEG && analyze_diff_expr.pl --samples  {params.replication} --matrix {params.matrix} -P 0.001 -C 2")
        shell("cd output/DEG && analyze_diff_expr.pl --samples {params.replication} --matrix {params.matrix} -P 0.01 -C 1")
rule summarize:
    input: 
        tpmcalc = "output/counts/tpmcalculator/tpmcalculator-merged.tsv",
        featureCounts_TPM = "output/counts/featureCounts/featureCounts.tpm.tsv",
        featureCounts_FPKM = "output/counts/featureCounts/featureCounts.fpkm.tsv",
        HTseq_TPM = "output/counts/htseq/htseq-count.tpm.tsv",
        HTseq_FPKM = "output/counts/htseq/htseq-count.fpkm.tsv"
    output: 
        "output/counts/tpmcalculator/tpmcalculator-merged.tsv.average.tsv",
        "output/counts/featureCounts/featureCounts.tpm.tsv.average.tsv",
        "output/counts/htseq/htseq-count.tpm.tsv.average.tsv"
    message: "--------------Summarizing Normalized Counts--------------"
    threads: config["threads"]["summarize"]
    run:
        # Compute summary statistics (average/standard deviation) from TPMcalculator TPM values
        shell("./scripts/summarizeNormalizedCounts.py Gene_Id {input.tpmcalc}")
        # Compute summary statistics (average/standard deviation) from HTseq FPKM/TPM values
        shell("./scripts/summarizeNormalizedCounts.py gene {input.HTseq_TPM}")
        shell("./scripts/summarizeNormalizedCounts.py gene {input.HTseq_FPKM}")
        # Compute summary statistics (average/standard deviation) from featureCounts FPKM/TPM values
        shell("./scripts/summarizeNormalizedCounts.py Geneid {input.featureCounts_TPM}")
        shell("./scripts/summarizeNormalizedCounts.py Geneid {input.featureCounts_FPKM}")

rule summarizeRSEM:
    input: input_DEG_RSEM
    output: 
        "output/counts/RSEM/RSEM_TPM.tsv.average.tsv",
        "output/counts/RSEM/RSEM_TPM.tsv"
    message: "------ Summarizing RSEM ------"
    run:
        # Make RSEM tpm/fpkm matrices
        shell("python ./scripts/makeRSEMMatrix.py RunsByExperiment.tsv output/counts/RSEM TPM")
        shell("python ./scripts/makeRSEMMatrix.py RunsByExperiment.tsv output/counts/RSEM FPKM")
        # Summarize RSEM data
        shell("./scripts/summarizeNormalizedCounts.py gene_id output/counts/RSEM/RSEM_TPM.tsv")
        shell("./scripts/summarizeNormalizedCounts.py gene_id output/counts/RSEM/RSEM_FPKM.tsv")

